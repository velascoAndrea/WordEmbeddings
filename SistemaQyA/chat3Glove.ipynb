{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Cargar el modelo de lenguaje en español de SpaCy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de preprocesamiento avanzado\n",
    "def advanced_preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/velasco/Documentos/Proyectos/MachineLearning/Tesis/SistemaQyA/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: What is the capital of France?\n",
      "Contextos más relevantes:\n",
      "1. \"\n",
      "\n",
      "\"Paris is the capital of France.\n",
      "2. Algiers became the capital of French Algeria.\n",
      "3. ===National government===\n",
      "\n",
      "As the capital of France, Paris is the seat of France's national government.\n"
     ]
    }
   ],
   "source": [
    "# Directorio donde están los archivos\n",
    "directory = \"ArchivosWiki\"\n",
    "\n",
    "# Preparar los datos\n",
    "sentences = []\n",
    "contexts = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, \"r\", encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Dividir el contenido en fragmentos más pequeños si es necesario\n",
    "        max_chunk_size = 100000  # Tamaño máximo de cada fragmento\n",
    "        content_chunks = [content[i:i+max_chunk_size] for i in range(0, len(content), max_chunk_size)]\n",
    "        \n",
    "        for chunk in content_chunks:\n",
    "            # Preprocesar el fragmento\n",
    "            tokens = advanced_preprocess(chunk)\n",
    "            sentences.append(tokens)\n",
    "            \n",
    "            # Dividir el fragmento en oraciones utilizando SpaCy\n",
    "            doc = nlp(chunk)\n",
    "            paragraphs = [sent.text.strip() for sent in doc.sents]\n",
    "            contexts.extend(paragraphs)\n",
    "\n",
    "# Crear un DataFrame con los contextos\n",
    "df = pd.DataFrame({'text': contexts})\n",
    "\n",
    "\n",
    "# Generar una matriz TF-IDF para ponderar los embeddings\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: advanced_preprocess(x), lowercase=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['text'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Crear un diccionario palabra: idf\n",
    "idf_dict = dict(zip(tfidf_feature_names, vectorizer.idf_))\n",
    "\n",
    "#Paso 1: Cargar los Embeddings de GloVe\n",
    "#Primero, necesitamos cargar los embeddings desde el archivo glove.6B.300d.txt:\n",
    "\n",
    "# Función para cargar los embeddings de GloVe\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            try:\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return embeddings_index\n",
    "\n",
    "# Cargar los embeddings\n",
    "glove_embeddings = load_glove_embeddings('./ModelosEmbeddings/Glove/glove.6B.300d.txt')\n",
    "\n",
    "\n",
    "#Paso 2: Modificar la Función para Obtener Embeddings de Oraciones\n",
    "#Actualiza la función get_weighted_sentence_embedding para utilizar los embeddings de GloVe:\n",
    "\n",
    "def get_weighted_sentence_embedding(sentence, embeddings_index, idf_dict, vector_size=300):\n",
    "    tokens = advanced_preprocess(sentence)\n",
    "    word_embeddings = []\n",
    "    weights = []\n",
    "    for word in tokens:\n",
    "        if word in embeddings_index and word in idf_dict:\n",
    "            word_embeddings.append(embeddings_index[word])\n",
    "            weights.append(idf_dict[word])\n",
    "    if not word_embeddings:\n",
    "        return np.zeros(vector_size)\n",
    "    word_embeddings = np.array(word_embeddings)\n",
    "    weights = np.array(weights).reshape(-1, 1)\n",
    "    weighted_average = np.sum(word_embeddings * weights, axis=0) / np.sum(weights)\n",
    "    return weighted_average\n",
    "\n",
    "\n",
    "# Generar embeddings para cada contexto usando GloVe\n",
    "df['embeddings'] = df['text'].apply(lambda x: get_weighted_sentence_embedding(x, glove_embeddings, idf_dict, vector_size=300))\n",
    "\n",
    "\n",
    "def find_most_relevant_contexts(question, df, embeddings_index, idf_dict, top_n=3, vector_size=300):\n",
    "    question_embedding = get_weighted_sentence_embedding(question, embeddings_index, idf_dict, vector_size)\n",
    "    context_embeddings = np.vstack(df['embeddings'].values)\n",
    "    similarities = cosine_similarity([question_embedding], context_embeddings)[0]\n",
    "    df['similarity'] = similarities\n",
    "    top_indices = df['similarity'].argsort()[-top_n:][::-1]\n",
    "    most_relevant_contexts = df.iloc[top_indices]['text'].tolist()\n",
    "    return most_relevant_contexts\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "# Encontrar los contextos más relevantes\n",
    "most_relevant_contexts = find_most_relevant_contexts(question, df, glove_embeddings, idf_dict, top_n=3, vector_size=300)\n",
    "\n",
    "# Imprimir los contextos más relevantes\n",
    "print(\"Pregunta:\", question)\n",
    "print(\"Contextos más relevantes:\")\n",
    "for idx, context in enumerate(most_relevant_contexts, 1):\n",
    "    print(f\"{idx}. {context}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUARDADO DE INFORMACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el DataFrame en un archivo pickle\n",
    "with open('context_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna de embeddings en una matriz numpy\n",
    "embeddings_matrix = np.vstack(df['embeddings'].values)\n",
    "\n",
    "# Guardar los embeddings en un archivo numpy\n",
    "#np.save('embeddingsGlove.npy', embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los textos y otros datos en un archivo CSV\n",
    "#df.drop('embeddings', axis=1).to_csv('context_dataGlove.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar idf_dict en un archivo pickle\n",
    "with open('idf_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(idf_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los embeddings de GloVe en un archivo pickle\n",
    "with open('glove_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(glove_embeddings, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LECTURA DE LOS ARCHIVOS GENERADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# Cargar el modelo de lenguaje\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Función de preprocesamiento\n",
    "def advanced_preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
    "    return tokens\n",
    "\n",
    "# Función para calcular el embedding ponderado por TF-IDF\n",
    "def get_weighted_sentence_embedding(sentence, embeddings_index, idf_dict, vector_size=300):\n",
    "    tokens = advanced_preprocess(sentence)\n",
    "    word_embeddings = []\n",
    "    weights = []\n",
    "    for word in tokens:\n",
    "        if word in embeddings_index and word in idf_dict:\n",
    "            word_embeddings.append(embeddings_index[word])\n",
    "            weights.append(idf_dict[word])\n",
    "    if not word_embeddings:\n",
    "        return np.zeros(vector_size)\n",
    "    word_embeddings = np.array(word_embeddings)\n",
    "    weights = np.array(weights).reshape(-1, 1)\n",
    "    weighted_average = np.sum(word_embeddings * weights, axis=0) / np.sum(weights)\n",
    "    return weighted_average\n",
    "\n",
    "# Función para encontrar los contextos más relevantes\n",
    "def find_most_relevant_contexts(question, df, embeddings_index, idf_dict, top_n=3, vector_size=300):\n",
    "    question_embedding = get_weighted_sentence_embedding(question, embeddings_index, idf_dict, vector_size)\n",
    "    context_embeddings = np.vstack(df['embeddings'].values)\n",
    "    similarities = cosine_similarity([question_embedding], context_embeddings)[0]\n",
    "    df['similarity'] = similarities\n",
    "    top_indices = df['similarity'].argsort()[-top_n:][::-1]\n",
    "    most_relevant_contexts = df.iloc[top_indices][['text', 'similarity']].to_dict(orient='records')\n",
    "    return most_relevant_contexts\n",
    "\n",
    "# Cargar los datos guardados\n",
    "with open('ModelosEmbeddings/Glove/idf_dict.pkl', 'rb') as f:\n",
    "    idf_dict = pickle.load(f)\n",
    "\n",
    "with open('ModelosEmbeddings/Glove/glove_embeddings.pkl', 'rb') as f:\n",
    "    glove_embeddings = pickle.load(f)\n",
    "\n",
    "df = pd.read_pickle('ModelosEmbeddings/Glove/context_embeddings.pkl')\n",
    "\n",
    "# Función para responder una pregunta\n",
    "def answer_question(question, top_n=3):\n",
    "    results = find_most_relevant_contexts(question, df, glove_embeddings, idf_dict, top_n=top_n, vector_size=300)\n",
    "    print(\"\\nPregunta:\", question)\n",
    "    print(\"Contextos más relevantes:\")\n",
    "    for idx, result in enumerate(results, 1):\n",
    "        print(f\"{idx}. {result['text']} (Similitud: {result['similarity']:.2f})\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "#question = \"What is the capital of France?\"\n",
    "#answer_question(question, top_n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def answer_question_glove(\n",
    "    df,\n",
    "    question,\n",
    "    glove_embeddings,\n",
    "    idf_dict,\n",
    "    top_n=3,\n",
    "    gpt_model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=150,\n",
    "    debug=False,\n",
    "    stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question using the most relevant contexts obtained from GloVe.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The dataframe containing text and embeddings.\n",
    "        question (str): The user's question.\n",
    "        glove_embeddings (dict): The GloVe embeddings loaded as a dictionary.\n",
    "        idf_dict (dict): Dictionary containing IDF values.\n",
    "        top_n (int): Number of top relevant contexts to retrieve.\n",
    "        gpt_model (str): The GPT model to use (default: \"gpt-3.5-turbo\").\n",
    "        max_tokens (int): Maximum tokens for GPT response.\n",
    "        debug (bool): If True, print debugging information.\n",
    "        stop_sequence: The stop sequence for GPT response.\n",
    "\n",
    "    Returns:\n",
    "        str: The GPT-generated response based on GloVe contexts.\n",
    "    \"\"\"\n",
    "    # Obtener los contextos más relevantes usando GloVe\n",
    "    relevant_contexts = find_most_relevant_contexts(question, df, glove_embeddings, idf_dict, top_n=top_n, vector_size=300)\n",
    "\n",
    "    # Combinar los contextos en un solo texto\n",
    "    context = \"\\n\".join([ctx['text'] for ctx in relevant_contexts])\n",
    "\n",
    "    if debug:\n",
    "        print(\"Contextos relevantes obtenidos de GloVe:\\n\")\n",
    "        print(context)\n",
    "        print(\"\\n---\\n\")\n",
    "\n",
    "    try:\n",
    "        # Crear una consulta a GPT con los contextos obtenidos\n",
    "        response = client.chat.completions.create(\n",
    "            model=gpt_model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Responde la pregunta basándote en el contexto proporcionado. Si no puedes responder basándote en el contexto, di 'Escribe AGENTE para más información.'\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"Contexto: {context}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Pregunta: {question}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar la respuesta: {e}\")\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGUNTAS FACTUALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pregunta 1: Who painted the Mona Lisa?\n",
      "Respuesta: Leonardo da Vinci painted the Mona Lisa.\n",
      "\n",
      "Pregunta 2: What is the capital of France?\n",
      "Respuesta: Respuesta: The capital of France is Paris.\n",
      "\n",
      "Pregunta 3: When did World War II begin?\n",
      "Respuesta: World War II began in September 1939.\n",
      "\n",
      "Pregunta 4: Who was the first man to walk on the Moon?\n",
      "Respuesta: Duke soon descended the ladder and joined Young on the surface, becoming the tenth person to walk on the Moon.\n",
      "\n",
      "Pregunta 5: What is the longest river in the world?\n",
      "Respuesta: Respuesta: El río Nilo ha sido históricamente considerado el río más largo del mundo, aunque esta afirmación ha sido cuestionada por investigaciones que sugieren que el río Amazonas es ligeramente más largo.\n",
      "\n",
      "Pregunta 6: Which country has the largest population?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 7: Who wrote 'One Hundred Years of Solitude'?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 8: What chemical element has the symbol 'O'?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 9: In what year was America discovered?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 10: What is the highest mountain in the world?\n",
      "Respuesta: The highest mountain in the world is Mount Everest, located in the Himalayas, with a height of 8848 meters.\n",
      "\n",
      "Pregunta 11: Who is the author of the theory of relativity?\n",
      "Respuesta: Respuesta: Albert Einstein es el autor de la teoría de la relatividad.\n",
      "\n",
      "Pregunta 12: What is the largest ocean in the world?\n",
      "Respuesta: El océano más grande del mundo es el Océano Pacífico.\n",
      "\n",
      "Pregunta 13: Which country won the 2018 FIFA World Cup?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 14: Which planet is known as the Red Planet?\n",
      "Respuesta: Marte es conocido como el Planeta Rojo.\n",
      "\n",
      "Pregunta 15: Who was the first president of the United States?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 16: How many colors are in a rainbow?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 17: On which continent is Egypt located?\n",
      "Respuesta: Egypt is located in Africa.\n",
      "\n",
      "Pregunta 18: What language is spoken in Brazil?\n",
      "Respuesta: La lengua hablada en Brasil es el portugués.\n",
      "\n",
      "Pregunta 19: What currency is used in Japan?\n",
      "Respuesta: Respuesta: The currency used in Japan is the yen.\n",
      "\n",
      "Pregunta 20: What language is spoken in Japan?\n",
      "Respuesta: Respuesta: Japanese is the language spoken in Japan.\n"
     ]
    }
   ],
   "source": [
    "# Lista de preguntas\n",
    "questions = [\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"When did World War II begin?\",\n",
    "    \"Who was the first man to walk on the Moon?\",\n",
    "    \"What is the longest river in the world?\",\n",
    "    \"Which country has the largest population?\",\n",
    "    \"Who wrote 'One Hundred Years of Solitude'?\",\n",
    "    \"What chemical element has the symbol 'O'?\",\n",
    "    \"In what year was America discovered?\",\n",
    "    \"What is the highest mountain in the world?\",\n",
    "    \"Who is the author of the theory of relativity?\",\n",
    "    \"What is the largest ocean in the world?\",\n",
    "    \"Which country won the 2018 FIFA World Cup?\",\n",
    "    \"Which planet is known as the Red Planet?\",\n",
    "    \"Who was the first president of the United States?\",\n",
    "    \"How many colors are in a rainbow?\",\n",
    "    \"On which continent is Egypt located?\",\n",
    "    \"What language is spoken in Brazil?\",\n",
    "    \"What currency is used in Japan?\",\n",
    "    \"What language is spoken in Japan?\"\n",
    "]\n",
    "\n",
    "\n",
    "# Iterar sobre las preguntas y obtener respuestas\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\nPregunta {i}: {question}\")\n",
    "    \n",
    "    # Llamar al método para generar la respuesta\n",
    "    response = answer_question_glove(\n",
    "         df=df,\n",
    "        question=question,\n",
    "        glove_embeddings=glove_embeddings,\n",
    "        idf_dict=idf_dict,\n",
    "        top_n=20,  # Obtener los 3 contextos más relevantes\n",
    "        gpt_model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=150,\n",
    "        debug=False  # Activa el modo de depuración para ver los contextos seleccionados\n",
    "    )\n",
    "    \n",
    "    # Imprimir la respuesta generada\n",
    "    print(f\"Respuesta: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGUNTAS CONTEXTUALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pregunta 1: What does 'Python' mean in programming?\n",
      "Respuesta: En programación, 'Python' se refiere a un lenguaje de programación de alto nivel y propósito general.\n",
      "\n",
      "Pregunta 2: What does 'Python' mean in zoology?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 3: What is Java in computer science?\n",
      "Respuesta: En computer science, Java es un lenguaje de programación que puede ser compilado en bytecode de Java y ejecutado en una Java Virtual Machine (JVM). También es parte de la plataforma Java, que incluye la JVM y varias APIs de Java.\n",
      "\n",
      "Pregunta 4: What is Java in geography?\n",
      "Respuesta: Java in geography refers to an island of Indonesia.\n",
      "\n",
      "Pregunta 5: What is the connection between the Sun and photosynthesis?\n",
      "Respuesta: La conexión entre el Sol y la fotosíntesis es que la energía del Sol es capturada por la fotosíntesis y utilizada por los organismos vivos para llevar a cabo este proceso. La fotosíntesis permite que la energía solar sea recolectada directamente por las formas de vida, lo que les permite convertirla en energía utilizable.\n",
      "\n",
      "Pregunta 6: How does global warming affect sea levels?\n",
      "Respuesta: Global warming causes a rise in sea levels due to anthropogenic warming of the global ocean combined with contributions of freshwater from retreating land ice. The increase in mean global temperature leads to the melting of ice caps and glaciers, which in turn adds more water to the oceans, resulting in a rise in sea levels.\n",
      "\n",
      "Pregunta 7: What does the melting of polar ice caps imply?\n",
      "Respuesta: La fusión de los casquetes de hielo polares implica el aumento del nivel del mar.\n",
      "\n",
      "Pregunta 8: What is the impact of climate change on agriculture?\n",
      "Respuesta: Climate change has had negative impacts on agriculture, particularly in the south of the country with a steppe climate. These impacts have made agricultural activity vulnerable to climate change and global warming, forcing farmers to change crops and planting times. The changing climate has affected yields and agricultural practices, making it necessary for farmers to adapt to the new conditions.\n",
      "\n",
      "Pregunta 9: What are the benefits of artificial intelligence in medicine?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 10: What does 'bank' mean in the financial context?\n",
      "Respuesta: En el contexto financiero, 'bank' se refiere a una institución financiera que se encarga de gestionar el dinero, ofrecer servicios financieros, y manejar la política monetaria de un país o una unión monetaria.\n",
      "\n",
      "Pregunta 11: What does 'bank' mean in the context of a park?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 12: How is electricity related to magnetism?\n",
      "Respuesta: Electricity is related to magnetism as both are part of the phenomenon of electromagnetism, as described by Maxwell's equations.\n",
      "\n",
      "Pregunta 13: What is quantum computing and how is it used?\n",
      "Respuesta: La computación cuántica es un área de investigación que combina disciplinas como la informática, la teoría de la información y la física cuántica. Se basa en los principios de la mecánica cuántica para realizar operaciones computacionales. Un ordenador cuántico es un tipo de ordenador que aprovecha los fenómenos cuánticos para realizar cálculos. Se ha sugerido que los algoritmos cuánticos, que son algoritmos que se ejecutan en un modelo realista de computación cuántica, pueden ser calculados de manera igualmente eficiente con la computación cuántica neuromórfica.\n",
      "\n",
      "Pregunta 14: How is cryptocurrency defined?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 15: What role does water play in the life cycle?\n",
      "Respuesta: El agua juega un papel importante en el ciclo de vida, ya que cambia de estado varias veces a lo largo de este ciclo. Además, la mayoría de los cereales necesitan agua regularmente en la etapa temprana de su ciclo de vida.\n",
      "\n",
      "Pregunta 16: What does the 'Industrial Revolution' mean in historical terms?\n",
      "Respuesta: En términos históricos, la 'Revolución Industrial' se refiere a un período de transición global de la economía humana hacia procesos de fabricación más extendidos, eficientes y estables que sucedieron a la Revolución Agrícola. Comenzó alrededor de 1760 en Gran Bretaña y se extendió a Europa continental y Estados Unidos, ocurriendo aproximadamente entre 1820 y 1840. La Revolución Industrial marcó un cambio significativo en la historia al impulsar la fabricación a gran escala y transformar la sociedad, la economía y la política.\n",
      "\n",
      "Pregunta 17: What is the relationship between capitalism and the free market?\n",
      "Respuesta: La relación entre el capitalismo y el libre mercado es que el libre mercado es un sistema económico en el cual los precios de bienes y servicios son determinados por la oferta y la demanda expresada por vendedores y compradores. Por otro lado, el capitalismo es un sistema económico en el cual los medios de producción y distribución son de propiedad privada y operan con fines de lucro. En muchos casos, el capitalismo se asocia con el libre mercado, ya que se considera que éste es la base de una sociedad libre y próspera.\n",
      "\n",
      "Pregunta 18: What does 'blockchain' mean in the technological context?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 19: What is the importance of photosynthesis in nature?\n",
      "Respuesta: La importancia de la fotosíntesis en la naturaleza radica en que es un sistema de procesos biológicos mediante el cual los organismos fotosintéticos, como la mayoría de las plantas, algas y cianobacterias, convierten la energía lumínica, típicamente del sol, en la energía química necesaria para alimentar sus actividades. La energía capturada por la fotosíntesis oxigénica y liberada por la respiración celular es la base de casi toda la vida en la Tierra. La fotosíntesis permite a los organismos producir su propio alimento y liberar oxígeno al ambiente, lo que ha\n",
      "\n",
      "Pregunta 20: What role does education play in economic development?\n",
      "Respuesta: La educación juega un papel crucial en el desarrollo económico al proporcionar una fuerza laboral calificada y capacitada, lo que a su vez impulsa la productividad y la innovación en una economía. Además, la educación puede fomentar el emprendimiento, mejorar las habilidades de los trabajadores y promover un mayor desarrollo social y económico en general.\n"
     ]
    }
   ],
   "source": [
    "# Lista de preguntas\n",
    "questions = [\n",
    "    \"What does 'Python' mean in programming?\",\n",
    "    \"What does 'Python' mean in zoology?\",\n",
    "    \"What is Java in computer science?\",\n",
    "    \"What is Java in geography?\",\n",
    "    \"What is the connection between the Sun and photosynthesis?\",\n",
    "    \"How does global warming affect sea levels?\",\n",
    "    \"What does the melting of polar ice caps imply?\",\n",
    "    \"What is the impact of climate change on agriculture?\",\n",
    "    \"What are the benefits of artificial intelligence in medicine?\",\n",
    "    \"What does 'bank' mean in the financial context?\",\n",
    "    \"What does 'bank' mean in the context of a park?\",\n",
    "    \"How is electricity related to magnetism?\",\n",
    "    \"What is quantum computing and how is it used?\",\n",
    "    \"How is cryptocurrency defined?\",\n",
    "    \"What role does water play in the life cycle?\",\n",
    "    \"What does the 'Industrial Revolution' mean in historical terms?\",\n",
    "    \"What is the relationship between capitalism and the free market?\",\n",
    "    \"What does 'blockchain' mean in the technological context?\",\n",
    "    \"What is the importance of photosynthesis in nature?\",\n",
    "    \"What role does education play in economic development?\"\n",
    "]\n",
    "\n",
    "# Iterar sobre las preguntas y obtener respuestas\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\nPregunta {i}: {question}\")\n",
    "    \n",
    "    # Llamar al método para generar la respuesta\n",
    "    response = answer_question_glove(\n",
    "         df=df,\n",
    "        question=question,\n",
    "        glove_embeddings=glove_embeddings,\n",
    "        idf_dict=idf_dict,\n",
    "        top_n=20,  # Obtener los 3 contextos más relevantes\n",
    "        gpt_model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=150,\n",
    "        debug=False  # Activa el modo de depuración para ver los contextos seleccionados\n",
    "    )\n",
    "    \n",
    "    # Imprimir la respuesta generada\n",
    "    print(f\"Respuesta: {response}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALOGIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Función para resolver analogías con embeddings GloVe\n",
    "def find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=1):\n",
    "    \"\"\"\n",
    "    Encuentra la palabra que completa la analogía: word_a es a word_b como word_c es a ?\n",
    "\n",
    "    Parámetros:\n",
    "        word_a (str): Primera palabra en la analogía (e.g., \"rey\").\n",
    "        word_b (str): Segunda palabra en la analogía (e.g., \"reina\").\n",
    "        word_c (str): Tercera palabra en la analogía (e.g., \"hombre\").\n",
    "        glove_embeddings (dict): Diccionario de embeddings de GloVe.\n",
    "        top_n (int): Número de palabras más cercanas a retornar.\n",
    "\n",
    "    Retorna:\n",
    "        list: Lista de palabras más cercanas junto con sus similitudes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir las palabras a minúsculas\n",
    "        word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "\n",
    "        # Verificar si las palabras están en el vocabulario\n",
    "        for word in [word_a, word_b, word_c]:\n",
    "            if word not in glove_embeddings:\n",
    "                return [f\"'{word}' no está en el vocabulario del modelo.\"]\n",
    "\n",
    "        # Calcular el vector resultante de la analogía\n",
    "        analogy_vector = glove_embeddings[word_a] - glove_embeddings[word_b] + glove_embeddings[word_c]\n",
    "\n",
    "        # Encontrar las palabras más similares al vector resultante\n",
    "        similarities = {\n",
    "            word: 1 - cosine(embedding, analogy_vector)\n",
    "            for word, embedding in glove_embeddings.items()\n",
    "            if word not in {word_a, word_b, word_c}\n",
    "        }\n",
    "\n",
    "        # Ordenar por similitud y seleccionar las mejores\n",
    "        sorted_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_words[:top_n]\n",
    "\n",
    "    except Exception as e:\n",
    "        return [f\"Error al procesar la analogía: {e}\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'king' es a 'queen' como 'man' es a:\n",
      "- himself (similitud: 0.5258)\n",
      "- brother (similitud: 0.5021)\n",
      "- father (similitud: 0.5020)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"king\"\n",
    "word_b = \"queen\"\n",
    "word_c = \"man\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'madrid' es a 'spain' como 'tokio' es a:\n",
      "- mitsui (similitud: 0.3884)\n",
      "- yasuda (similitud: 0.3713)\n",
      "- wilsher (similitud: 0.3638)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"madrid\"\n",
    "word_b = \"spain\"\n",
    "word_c = \"tokio\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'day' es a 'sunny' como 'night' es a:\n",
      "- week (similitud: 0.6522)\n",
      "- friday (similitud: 0.6124)\n",
      "- after (similitud: 0.6091)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"day\"\n",
    "word_b = \"sunny\"\n",
    "word_c = \"night\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'spoon' es a 'soup' como 'fork' es a:\n",
      "- spatula (similitud: 0.5002)\n",
      "- forks (similitud: 0.4579)\n",
      "- tines (similitud: 0.4309)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"spoon\"\n",
    "word_b = \"soup\"\n",
    "word_c = \"fork\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'apple' es a 'fruit' como 'dog' es a:\n",
      "- cat (similitud: 0.4752)\n",
      "- dogs (similitud: 0.4635)\n",
      "- iphone (similitud: 0.4492)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"apple\"\n",
    "word_b = \"fruit\"\n",
    "word_c = \"dog\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'eye' es a 'see' como 'ear' es a:\n",
      "- ears (similitud: 0.5975)\n",
      "- nose (similitud: 0.5061)\n",
      "- throat (similitud: 0.4963)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"eye\"\n",
    "word_b = \"see\"\n",
    "word_c = \"ear\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car' es a 'fuel' como 'human' es a:\n",
      "- rights (similitud: 0.4648)\n",
      "- woman (similitud: 0.4481)\n",
      "- man (similitud: 0.4365)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"car\"\n",
    "word_b = \"fuel\"\n",
    "word_c = \"human\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bird' es a 'flying' como 'fish' es a:\n",
      "- poultry (similitud: 0.5474)\n",
      "- birds (similitud: 0.5456)\n",
      "- seafood (similitud: 0.5294)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"bird\"\n",
    "word_b = \"flying\"\n",
    "word_c = \"fish\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'computer' es a 'processor' como 'human' es a:\n",
      "- experts (similitud: 0.5135)\n",
      "- scientists (similitud: 0.4921)\n",
      "- rights (similitud: 0.4825)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"computer\"\n",
    "word_b = \"processor\"\n",
    "word_c = \"human\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'book' es a 'read' como 'movie' es a:\n",
      "- film (similitud: 0.7491)\n",
      "- sequel (similitud: 0.6579)\n",
      "- films (similitud: 0.6530)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTAS DE ANALOGÍAS\n",
    "word_a = \"book\"\n",
    "word_b = \"read\"\n",
    "word_c = \"movie\"\n",
    "\n",
    "result = find_analogy_glove(word_a, word_b, word_c, glove_embeddings, top_n=3)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"'{word_a}' es a '{word_b}' como '{word_c}' es a:\")\n",
    "for word, similarity in result:\n",
    "    print(f\"- {word} (similitud: {similarity:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
