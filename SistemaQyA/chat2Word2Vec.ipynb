{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo de lenguaje en ingles de SpaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#es_core_news_sm\n",
    "# Función de preprocesamiento avanzado\n",
    "def advanced_preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/velasco/Documentos/Proyectos/MachineLearning/Tesis/SistemaQyA/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: Who painted the Mona Lisa?\n",
      "Contextos más relevantes:\n",
      "1. The Mona Lisa wears green in her portrait, as does the bride in the Arnolfini portrait by Jan van Eyck.\n",
      "2. Biographer Bob Colacello provides some details on Andy's \"piss paintings\":\n",
      "\n",
      "Warhol's 1982 portrait of Basquiat, Jean-Michel Basquiat, is a silkscreen over an oxidized copper \"piss painting\".\n",
      "3. Saroyan also painted.\n"
     ]
    }
   ],
   "source": [
    "# Directorio donde están los archivos\n",
    "directory = \"ArchivosWiki\"\n",
    "\n",
    "# Preparar los datos\n",
    "sentences = []\n",
    "contexts = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, \"r\", encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Dividir el contenido en fragmentos más pequeños\n",
    "        # Puedes dividir por líneas, párrafos o un número fijo de caracteres\n",
    "        max_chunk_size = 100000  # Tamaño máximo de cada fragmento\n",
    "        content_chunks = [content[i:i+max_chunk_size] for i in range(0, len(content), max_chunk_size)]\n",
    "        \n",
    "        for chunk in content_chunks:\n",
    "            # Preprocesar el fragmento\n",
    "            tokens = advanced_preprocess(chunk)\n",
    "            sentences.append(tokens)\n",
    "            \n",
    "            # Dividir el fragmento en oraciones utilizando SpaCy\n",
    "            doc = nlp(chunk)\n",
    "            paragraphs = [sent.text.strip() for sent in doc.sents]\n",
    "            contexts.extend(paragraphs)\n",
    "\n",
    "# Entrenar el modelo Word2Vec\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec_wiki.model\")\n",
    "\n",
    "# Cargar el modelo Word2Vec\n",
    "model = Word2Vec.load(\"word2vec_wiki.model\")\n",
    "\n",
    "# Crear un DataFrame con los contextos\n",
    "df = pd.DataFrame({'text': contexts})\n",
    "\n",
    "# Generar una matriz TF-IDF para ponderar los embeddings\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: advanced_preprocess(x), lowercase=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['text'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Crear un diccionario palabra: idf\n",
    "idf_dict = dict(zip(tfidf_feature_names, vectorizer.idf_))\n",
    "\n",
    "# Función para obtener el embedding promedio ponderado por TF-IDF de una oración\n",
    "def get_weighted_sentence_embedding(sentence, model, idf_dict):\n",
    "    tokens = advanced_preprocess(sentence)\n",
    "    word_embeddings = []\n",
    "    weights = []\n",
    "    for word in tokens:\n",
    "        if word in model.wv.key_to_index and word in idf_dict:\n",
    "            word_embeddings.append(model.wv[word])\n",
    "            weights.append(idf_dict[word])\n",
    "    if not word_embeddings:\n",
    "        return np.zeros(model.vector_size)\n",
    "    word_embeddings = np.array(word_embeddings)\n",
    "    weights = np.array(weights).reshape(-1,1)\n",
    "    weighted_average = np.sum(word_embeddings * weights, axis=0) / np.sum(weights)\n",
    "    return weighted_average\n",
    "\n",
    "# Generar embeddings para cada contexto\n",
    "df['embeddings'] = df['text'].apply(lambda x: get_weighted_sentence_embedding(x, model, idf_dict))\n",
    "\n",
    "# Función para encontrar los contextos más relevantes\n",
    "def find_most_relevant_contexts(question, df, model, idf_dict, top_n=3):\n",
    "    question_embedding = get_weighted_sentence_embedding(question, model, idf_dict)\n",
    "    context_embeddings = np.vstack(df['embeddings'].values)\n",
    "    similarities = cosine_similarity([question_embedding], context_embeddings)[0]\n",
    "    df['similarity'] = similarities\n",
    "    top_indices = df['similarity'].argsort()[-top_n:][::-1]\n",
    "    most_relevant_contexts = df.iloc[top_indices]['text'].tolist()\n",
    "    return most_relevant_contexts\n",
    "\n",
    "# Ejemplo de uso\n",
    "question = \"Who painted the Mona Lisa?\"\n",
    "most_relevant_contexts = find_most_relevant_contexts(question, df, model, idf_dict, top_n=3)\n",
    "\n",
    "# Imprimir los contextos más relevantes\n",
    "print(\"Pregunta:\", question)\n",
    "print(\"Contextos más relevantes:\")\n",
    "for idx, context in enumerate(most_relevant_contexts, 1):\n",
    "    print(f\"{idx}. {context}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUARDADO DE INFORMACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el DataFrame 'df' con los embeddings\n",
    "df.to_pickle('df_with_embeddings.pkl')\n",
    "\n",
    "# Guardar el diccionario 'idf_dict'\n",
    "with open('idf_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(idf_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los embeddings como un archivo numpy\n",
    "embeddings_array = np.vstack(df['embeddings'].values)\n",
    "np.save('embeddings.npy', embeddings_array)\n",
    "\n",
    "# Guardar los textos\n",
    "#df['text'].to_csv('texts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURA DE LOS ARCHIVOS GENERADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Cargar variables de entorno desde un archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Leer la API key desde las variables de entorno\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Cargar el modelo de lenguaje en ingles de SpaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#es_core_news_sm\n",
    "# Función de preprocesamiento avanzado\n",
    "def advanced_preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Cargar el modelo de Word2Vec\n",
    "model = Word2Vec.load(\"ModelosEmbeddings/word2vec_wiki.model\")\n",
    "\n",
    "# Cargar el DataFrame con los textos y sus embeddings\n",
    "df = pd.read_pickle('ModelosEmbeddings/df_with_embeddings.pkl')\n",
    "\n",
    "# Cargar el diccionario 'idf_dict'\n",
    "with open('ModelosEmbeddings/idf_dict.pkl', 'rb') as f:\n",
    "    idf_dict = pickle.load(f)\n",
    "\n",
    "# Cargar los embeddings como un archivo numpy\n",
    "embeddings_array = np.load('ModelosEmbeddings/embeddings.npy')\n",
    "\n",
    "# Actualizar los embeddings en el DataFrame (opcional)\n",
    "df['embeddings'] = list(embeddings_array)\n",
    "\n",
    "# Función para calcular el embedding de una pregunta\n",
    "def get_weighted_sentence_embedding(sentence, model, idf_dict):\n",
    "    tokens = advanced_preprocess(sentence)\n",
    "    word_embeddings = []\n",
    "    weights = []\n",
    "    for word in tokens:\n",
    "        if word in model.wv.key_to_index and word in idf_dict:\n",
    "            word_embeddings.append(model.wv[word])\n",
    "            weights.append(idf_dict[word])\n",
    "    if not word_embeddings:\n",
    "        return np.zeros(model.vector_size)\n",
    "    word_embeddings = np.array(word_embeddings)\n",
    "    weights = np.array(weights).reshape(-1, 1)\n",
    "    weighted_average = np.sum(word_embeddings * weights, axis=0) / np.sum(weights)\n",
    "    return weighted_average\n",
    "\n",
    "# Función para encontrar los contextos más relevantes\n",
    "def find_most_relevant_contexts(question, df, model, idf_dict, top_n=3):\n",
    "    question_embedding = get_weighted_sentence_embedding(question, model, idf_dict)\n",
    "    context_embeddings = np.vstack(df['embeddings'].values)\n",
    "    similarities = cosine_similarity([question_embedding], context_embeddings)[0]\n",
    "    df['similarity'] = similarities\n",
    "    top_indices = df['similarity'].argsort()[-top_n:][::-1]\n",
    "    most_relevant_contexts = df.iloc[top_indices]['text'].tolist()\n",
    "    return most_relevant_contexts\n",
    "\n",
    "def answer_question_word2vec(\n",
    "    df,\n",
    "    question,\n",
    "    word2vec_model,\n",
    "    idf_dict,\n",
    "    top_n=3,\n",
    "    gpt_model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=150,\n",
    "    debug=False,\n",
    "    stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question using the most relevant contexts obtained from Word2Vec.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The dataframe containing text and embeddings.\n",
    "        question (str): The user's question.\n",
    "        word2vec_model: The trained Word2Vec model.\n",
    "        idf_dict (dict): Dictionary containing IDF values.\n",
    "        top_n (int): Number of top relevant contexts to retrieve.\n",
    "        gpt_model (str): The GPT model to use (default: \"gpt-3.5-turbo\").\n",
    "        max_tokens (int): Maximum tokens for GPT response.\n",
    "        debug (bool): If True, print debugging information.\n",
    "        stop_sequence: The stop sequence for GPT response.\n",
    "\n",
    "    Returns:\n",
    "        str: The GPT-generated response based on Word2Vec contexts.\n",
    "    \"\"\"\n",
    "    # Obtener los contextos más relevantes usando Word2Vec\n",
    "    relevant_contexts = find_most_relevant_contexts(question, df, word2vec_model, idf_dict, top_n=top_n)\n",
    "\n",
    "    # Combinar los contextos en un solo texto\n",
    "    context = \"\\n\".join(relevant_contexts)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Contextos relevantes obtenidos de Word2Vec:\\n\")\n",
    "        print(context)\n",
    "        print(\"\\n---\\n\")\n",
    "\n",
    "    try:\n",
    "        # Crear una consulta a GPT con los contextos obtenidos\n",
    "        response = client.chat.completions.create(\n",
    "            model=gpt_model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Responde la pregunta basándote en el contexto proporcionado. Si no puedes responder basándote en el contexto, di 'Escribe AGENTE para más información.'\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"Contexto: {context}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Pregunta: {question}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar la respuesta: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGUNTAS FACTUALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pregunta 1: Who painted the Mona Lisa?\n",
      "Respuesta: Leonardo da Vinci painted the Mona Lisa.\n",
      "\n",
      "Pregunta 2: What is the capital of France?\n",
      "Respuesta: La capital de Francia es París.\n",
      "\n",
      "Pregunta 3: When did World War II begin?\n",
      "Respuesta: La Segunda Guerra Mundial comenzó en 1939.\n",
      "\n",
      "Pregunta 4: Who was the first man to walk on the Moon?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 5: What is the longest river in the world?\n",
      "Respuesta: La respuesta basada en el contexto proporcionado es: El río Amazonas es el río más largo del mundo.\n",
      "\n",
      "Pregunta 6: Which country has the largest population?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 7: Who wrote 'One Hundred Years of Solitude'?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 8: What chemical element has the symbol 'O'?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 9: In what year was America discovered?\n",
      "Respuesta: Vespucci explored South America between 1497 and 1502, and was the first European to suggest that the Americas represented a landmass not then known to Europeans.\n",
      "\n",
      "Pregunta 10: What is the highest mountain in the world?\n",
      "Respuesta: Respuesta: El monte Everest es la montaña más alta del mundo, con una altura de 8848 metros sobre el nivel del mar.\n",
      "\n",
      "Pregunta 11: Who is the author of the theory of relativity?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 12: What is the largest ocean in the world?\n",
      "Respuesta: The largest ocean in the world is the Pacific Ocean.\n",
      "\n",
      "Pregunta 13: Which country won the 2018 FIFA World Cup?\n",
      "Respuesta: Germany became the first nation to win the new trophy for the third time when they won the 2014 FIFA World Cup.\n",
      "\n",
      "Pregunta 14: Which planet is known as the Red Planet?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 15: Who was the first president of the United States?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 16: How many colors are in a rainbow?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 17: On which continent is Egypt located?\n",
      "Respuesta: Egypt is located on two continents: Africa and Asia.\n",
      "\n",
      "Pregunta 18: What language is spoken in Brazil?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 19: What currency is used in Japan?\n",
      "Respuesta: La moneda utilizada en Japón es el yen japonés.\n",
      "\n",
      "Pregunta 20: What language is spoken in Japan?\n",
      "Respuesta: Japanese is spoken in Japan.\n"
     ]
    }
   ],
   "source": [
    "# Lista de preguntas\n",
    "questions = [\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"When did World War II begin?\",\n",
    "    \"Who was the first man to walk on the Moon?\",\n",
    "    \"What is the longest river in the world?\",\n",
    "    \"Which country has the largest population?\",\n",
    "    \"Who wrote 'One Hundred Years of Solitude'?\",\n",
    "    \"What chemical element has the symbol 'O'?\",\n",
    "    \"In what year was America discovered?\",\n",
    "    \"What is the highest mountain in the world?\",\n",
    "    \"Who is the author of the theory of relativity?\",\n",
    "    \"What is the largest ocean in the world?\",\n",
    "    \"Which country won the 2018 FIFA World Cup?\",\n",
    "    \"Which planet is known as the Red Planet?\",\n",
    "    \"Who was the first president of the United States?\",\n",
    "    \"How many colors are in a rainbow?\",\n",
    "    \"On which continent is Egypt located?\",\n",
    "    \"What language is spoken in Brazil?\",\n",
    "    \"What currency is used in Japan?\",\n",
    "    \"What language is spoken in Japan?\"\n",
    "]\n",
    "\n",
    "\n",
    "# Iterar sobre las preguntas y obtener respuestas\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\nPregunta {i}: {question}\")\n",
    "    \n",
    "    # Llamar al método para generar la respuesta\n",
    "    response = answer_question_word2vec(\n",
    "        df=df,\n",
    "        question=question,\n",
    "        word2vec_model=model,\n",
    "        idf_dict=idf_dict,\n",
    "        top_n=20,  # Obtener los contextos más relevantes\n",
    "        gpt_model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=150,\n",
    "        debug=False  # Desactiva el modo de depuración para respuestas limpias\n",
    "    )\n",
    "    \n",
    "    # Imprimir la respuesta generada\n",
    "    print(f\"Respuesta: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGUNTAS CONTEXTUALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pregunta 1: What does 'Python' mean in programming?\n",
      "Respuesta: Python is a high-level, general-purpose programming language.\n",
      "\n",
      "Pregunta 2: What does 'Python' mean in zoology?\n",
      "Respuesta: En zoología, \"Python\" se refiere a una serpiente constrictora no venenosa que pertenece a la familia Pythonidae.\n",
      "\n",
      "Pregunta 3: What is Java in computer science?\n",
      "Respuesta: Java in computer science is a programming language that allows for the development of software applications that can run on any computer with a Java Virtual Machine installed. This feature enables Java programs to be platform-independent, meaning they can run on different types of computers without needing to be rewritten for each specific system.\n",
      "\n",
      "Pregunta 4: What is Java in geography?\n",
      "Respuesta: Java in geography refers to an island of Indonesia.\n",
      "\n",
      "Pregunta 5: What is the connection between the Sun and photosynthesis?\n",
      "Respuesta: La conexión entre el Sol y la fotosíntesis es que las células fotosintéticas utilizan la energía del Sol para separar el hidrógeno del agua.\n",
      "\n",
      "Pregunta 6: How does global warming affect sea levels?\n",
      "Respuesta: Global warming affects sea levels by causing the warming of the global ocean, which combined with contributions of freshwater from retreating land ice, leads to a global rise in sea level. The increase in temperature, known as global warming, contributes to the melting of glaciers, rising sea levels, and changes in the quality of water. The United Nations Intergovernmental Panel on Climate Change predicts that sea levels will rise by about 50 cm (20 in) by 2100 due to global warming, with further rises being inevitable.\n",
      "\n",
      "Pregunta 7: What does the melting of polar ice caps imply?\n",
      "Respuesta: La fusión de los casquetes de hielo polares implica un aumento en el nivel del mar, lo cual puede tener consecuencias graves para las comunidades costeras y el medio ambiente en general. Además, la fusión de los casquetes de hielo polares también puede contribuir al cambio climático al liberar grandes cantidades de agua dulce en los océanos, alterando los patrones climáticos globales.\n",
      "\n",
      "Pregunta 8: What is the impact of climate change on agriculture?\n",
      "Respuesta: El impacto del cambio climático en la agricultura incluye la necesidad de que los agricultores cambien los cultivos que plantan y cuándo los plantan, así como la alteración de los patrones de lluvia que afectan la producción agrícola. En áreas con un clima de estepa, como en el sur de un país mencionado, los impactos negativos del cambio climático en la agricultura son especialmente significativos. Además, se espera que el cambio climático tenga un impacto severo en la economía de ciertos países, especialmente en sectores como la agricultura, la pesca y la silvicultura.\n",
      "\n",
      "Pregunta 9: What are the benefits of artificial intelligence in medicine?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 10: What does 'bank' mean in the financial context?\n",
      "Respuesta: En el contexto financiero, 'bank' se refiere a una institución financiera que se dedica a recibir depósitos, otorgar créditos, facilitar pagos, entre otros servicios financieros.\n",
      "\n",
      "Pregunta 11: What does 'bank' mean in the context of a park?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 12: How is electricity related to magnetism?\n",
      "Respuesta: Electricity and magnetism are fundamentally interlinked, as proposed by Faraday and further supported by Einstein's theory of special relativity. Faraday believed that all forms of electricity being studied at the time (voltaic, magnetic, thermal, and animal) were essentially the same. This connection between electricity and magnetism is also evident in various experiments conducted by scientists like Ørsted and Faraday, where they used different forms of electricity to produce magnetic effects.\n",
      "\n",
      "Pregunta 13: What is quantum computing and how is it used?\n",
      "Respuesta: Quantum computing is an area of research that combines computer science, information theory, and quantum physics. It is based on the principles of quantum mechanics and uses quantum bits (qubits) to perform computations. Quantum computing is used to solve complex problems that are beyond the capabilities of classical computers, such as cryptography, optimization, and simulations of quantum systems.\n",
      "\n",
      "Pregunta 14: How is cryptocurrency defined?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 15: What role does water play in the life cycle?\n",
      "Respuesta: Water plays a crucial role in various life cycles, such as providing the necessary environment for the development of organisms, enabling the growth of plants, and facilitating the circulation of nutrients. It is essential for the survival and reproduction of many species, making it a fundamental element in the life cycle of numerous organisms.\n",
      "\n",
      "Pregunta 16: What does the 'Industrial Revolution' mean in historical terms?\n",
      "Respuesta: En términos históricos, la 'Revolución Industrial' se refiere a un período de transición global de la economía humana hacia procesos de fabricación más extendidos, eficientes y estables que sucedieron a la Revolución Agrícola, comenzando en Gran Bretaña y extendiéndose a Europa continental y Estados Unidos, y que ocurrió aproximadamente entre 1760 y alrededor de 1820-1840. La Revolución Industrial marcó un cambio significativo en la forma en que se producían bienes y servicios, impulsando el desarrollo de la tecnología, la urbanización y la economía de mercado.\n",
      "\n",
      "Pregunta 17: What is the relationship between capitalism and the free market?\n",
      "Respuesta: La relación entre el capitalismo y el libre mercado es que el capitalismo se basa en la propiedad privada de los medios de producción y la búsqueda de beneficios a través de la inversión y la acumulación de capital, mientras que el libre mercado es un sistema económico en el que los precios de bienes y servicios son determinados por la oferta y la demanda expresadas por vendedores y compradores. En este contexto, algunos defensores del capitalismo, como los partidarios del capitalismo de libre mercado, ven al libre mercado como la base de una sociedad libre y próspera.\n",
      "\n",
      "Pregunta 18: What does 'blockchain' mean in the technological context?\n",
      "Respuesta: Escribe AGENTE para más información.\n",
      "\n",
      "Pregunta 19: What is the importance of photosynthesis in nature?\n",
      "Respuesta: La importancia de la fotosíntesis en la naturaleza radica en que es un proceso fundamental para las plantas y muchos otros organismos, ya que les permite convertir la luz solar en energía química, la cual es utilizada para alimentar sus funciones vitales. La fotosíntesis también desempeña un papel crucial en el ciclo global del carbono, ayudando a regular la cantidad de dióxido de carbono en la atmósfera y produciendo oxígeno como subproducto.\n",
      "\n",
      "Pregunta 20: What role does education play in economic development?\n",
      "Respuesta: La educación juega un papel crucial en el desarrollo económico, ya que ayuda a formar una fuerza laboral calificada, fomenta la innovación y el emprendimiento, y contribuye al crecimiento económico a largo plazo. Además, la educación puede aumentar la productividad de los trabajadores, mejorar la competitividad de una nación en la economía global y reducir la desigualdad económica.\n"
     ]
    }
   ],
   "source": [
    "# Lista de preguntas\n",
    "questions = [\n",
    "    \"What does 'Python' mean in programming?\",\n",
    "    \"What does 'Python' mean in zoology?\",\n",
    "    \"What is Java in computer science?\",\n",
    "    \"What is Java in geography?\",\n",
    "    \"What is the connection between the Sun and photosynthesis?\",\n",
    "    \"How does global warming affect sea levels?\",\n",
    "    \"What does the melting of polar ice caps imply?\",\n",
    "    \"What is the impact of climate change on agriculture?\",\n",
    "    \"What are the benefits of artificial intelligence in medicine?\",\n",
    "    \"What does 'bank' mean in the financial context?\",\n",
    "    \"What does 'bank' mean in the context of a park?\",\n",
    "    \"How is electricity related to magnetism?\",\n",
    "    \"What is quantum computing and how is it used?\",\n",
    "    \"How is cryptocurrency defined?\",\n",
    "    \"What role does water play in the life cycle?\",\n",
    "    \"What does the 'Industrial Revolution' mean in historical terms?\",\n",
    "    \"What is the relationship between capitalism and the free market?\",\n",
    "    \"What does 'blockchain' mean in the technological context?\",\n",
    "    \"What is the importance of photosynthesis in nature?\",\n",
    "    \"What role does education play in economic development?\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Iterar sobre las preguntas y obtener respuestas\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\nPregunta {i}: {question}\")\n",
    "    \n",
    "    # Llamar al método para generar la respuesta\n",
    "    response = answer_question_word2vec(\n",
    "        df=df,\n",
    "        question=question,\n",
    "        word2vec_model=model,\n",
    "        idf_dict=idf_dict,\n",
    "        top_n=20,  # Obtener los contextos más relevantes\n",
    "        gpt_model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=150,\n",
    "        debug=False  # Desactiva el modo de depuración para respuestas limpias\n",
    "    )\n",
    "    \n",
    "    # Imprimir la respuesta generada\n",
    "    print(f\"Respuesta: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGUNTAS ANALOGICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def find_analogy(word_a, word_b, word_c, model, top_n=1):\n",
    "    \"\"\"\n",
    "    Encuentra las palabras que completan la analogía: word_a es a word_b como word_c es a ?\n",
    "    \n",
    "    Parámetros:\n",
    "        word_a (str): Primera palabra (e.g., \"king\").\n",
    "        word_b (str): Segunda palabra (e.g., \"queen\").\n",
    "        word_c (str): Tercera palabra (e.g., \"man\").\n",
    "        model: Modelo Word2Vec ya entrenado.\n",
    "        top_n (int): Número de palabras más cercanas a retornar.\n",
    "    \n",
    "    Retorna:\n",
    "        list: Lista de las palabras más cercanas junto con su similitud.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir las palabras a minúsculas\n",
    "        word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "        \n",
    "        # Verificar si las palabras están en el vocabulario\n",
    "        for word in [word_a, word_b, word_c]:\n",
    "            if word not in model.wv.key_to_index:\n",
    "                return [f\"'{word}' no está en el vocabulario del modelo.\"]\n",
    "        \n",
    "        # Calcular el vector resultante para la analogía\n",
    "        analogy_vector = model.wv[word_a] - model.wv[word_b] + model.wv[word_c]\n",
    "        \n",
    "        # Encontrar las palabras más similares al vector resultante\n",
    "        similar_words = model.wv.similar_by_vector(analogy_vector, topn=top_n + 3)  # Extraemos más palabras para filtrar\n",
    "        # Excluir las palabras originales de la analogía\n",
    "        filtered_words = [(word, similarity) for word, similarity in similar_words if word not in {word_a, word_b, word_c}]\n",
    "        \n",
    "        return filtered_words[:top_n]\n",
    "\n",
    "    except KeyError as e:\n",
    "        return [f\"Error: {e}\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        return [f\"Error inesperado: {e}\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king es a queen como man es a: [('soldier', 0.5685295462608337), ('warrior', 0.5266982316970825), ('vortigern', 0.5246458649635315)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 1\n",
    "spanish_question = \"Rey es a reina como hombre es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"king\", \"queen\", \"man\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "madrid es a spain como tokio es a: [('chelsea', 0.5345818400382996), ('fulham', 0.5259823203086853), ('luton', 0.48761096596717834)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 2\n",
    "spanish_question = \"Madrid es a España como Tokio es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"madrid\", \"spain\", \"tokio\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day es a sunny como night es a: [('week', 0.8130009770393372), ('hour', 0.76027512550354), ('morning', 0.7474613785743713)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 3\n",
    "spanish_question = \"Día es a sol como noche es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"day\", \"sunny\", \"night\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spoon es a soup como fork es a: [('block', 0.5301869511604309), ('fishermans', 0.5300419926643372), ('stack', 0.524989128112793)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 4\n",
    "spanish_question = \"La cuchara es a sopa como tenedor es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"spoon\", \"soup\", \"fork\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple es a fruit como dog es a: [('kermit', 0.5665644407272339), ('trs-80', 0.5645706653594971), ('capcom', 0.5327814221382141)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 5\n",
    "spanish_question = \"Manzana es a fruta como perro es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"apple\", \"fruit\", \"dog\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye es a see como ear es a: [('eyelid', 0.7427768111228943), ('fingertip', 0.7015135288238525), ('nostril', 0.6950225234031677)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 6\n",
    "spanish_question = \"Ojo es a ver cómo oreja es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"eye\", \"see\", \"ear\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car es a fuel como human es a: [('person', 0.5392000079154968), ('individual', 0.47591862082481384), ('universal', 0.4596824049949646)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 7\n",
    "spanish_question = \"El carro es a combustible como humano es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"car\", \"fuel\", \"human\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird es a flying como fish es a: [('salmon', 0.7940330505371094), ('seabird', 0.7700880765914917), ('crocodile', 0.7623776197433472)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 8\n",
    "spanish_question = \"Ave es a volar como pez es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"bird\", \"flying\", \"fish\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer es a processor como human es a: [('animal', 0.5930473804473877), ('sentient', 0.5728640556335449), ('humanity', 0.5690764784812927)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 9\n",
    "spanish_question = \"Computadora es a procesador como humano es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"computer\", \"processor\", \"human\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book es a read como movie es a: [('film', 0.7438424229621887), ('sequel', 0.684289813041687), ('trilogy', 0.6735404133796692)]\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 10\n",
    "spanish_question = \"Libro es a leer como película es a ¿qué?\"\n",
    "\n",
    "word_a, word_b, word_c = \"book\", \"read\", \"movie\" # Palabras Extraidas\n",
    "\n",
    "# Resolver la analogía\n",
    "result = find_analogy(word_a, word_b, word_c, model, top_n=3)\n",
    "\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"{word_a} es a {word_b} como {word_c} es a: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
